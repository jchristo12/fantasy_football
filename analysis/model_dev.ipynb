{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Model Development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://raw.githubusercontent.com/jchristo12/fantasy_football/master/data/full_data.csv\n",
    "df = pd.read_csv('https://github.com/jchristo12/fantasy_football/blob/master/data/full_data.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pk', 'gid', 'seas', 'wk', 'player', 'fname', 'lname', 'full_name',\n",
       "       'team', 'pos1',\n",
       "       ...\n",
       "       'ou', 'sprv', 'ptsv', 'ptsh', 'udog', 'gen_cond', 'udog_binary',\n",
       "       'gen_dv', 'def_team', 'f_pts'],\n",
       "      dtype='object', length=171)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that have NaN for the shifted variables\n",
    "df_clean = df[~df.loc[:,'seas_pa':'seas_tdret'].isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are only focused on offensive players right now. Therefore, we will specifiy the positions we want to retain in the data and remove everyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#store positions we are concerned about; will use these to filter out \n",
    "pos_of_interest = ['QB', 'RB', 'WR', 'TE']\n",
    "#filter out positions we don't care about\n",
    "df_clean2 = df_clean[df_clean['pos1'].isin(pos_of_interest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert each column to the appropriate data type (i.e. make the categorical data categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the column types\n",
    "col_dtypes = {'category': ['seas', 'wk', 'pos1', 'team', 'udog', 'v', 'h', 'day', 'stad', 'wdir',\n",
    "                          'surf', 'gen_cond', 'gen_dv', 'def_team']}\n",
    "#flip the key and values around so they will work in the argument for 'astype()'\n",
    "col_dtypes_alt = {old: new for new, old_all in col_dtypes.items() for old in old_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df_clean2.astype(col_dtypes_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove rookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store dataframe of non-rookies\n",
    "df_clean2_vet = df_clean2.loc[df_clean2['exp']!=1, :]\n",
    "#store dataframe of rookie data\n",
    "df_clean2_rook = df_clean2.loc[df_clean2['exp']==1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segment out the WR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-rookies data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wr = df_clean2_vet.loc[df_clean2_vet['pos1']=='WR', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only focus on week 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wr10 = df_wr#.loc[df_wr['wk'] == 10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28605, 171)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wr10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only focusing on the WR data right now. Will need to build this so that each action is extendable to the other positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the random seed for reproducability\n",
    "random.seed(837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break out the data between training and test\n",
    "train_wr, test_wr = train_test_split(df_wr10, train_size=0.75, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21453, 171) (7152, 171)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data\n",
    "print(train_wr.shape, test_wr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a series of percent of missing data\n",
    "missing_data_pct = train_wr.isna().sum() / train_wr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all columns with missing data that is greater than 25%\n",
    "missing_data_pct[missing_data_pct > 0.25].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp            0.169673\n",
       "last_pa         0.120076\n",
       "last_tdr        0.120076\n",
       "last_ret        0.120076\n",
       "last_tdrec      0.120076\n",
       "last_recy       0.120076\n",
       "last_rec        0.120076\n",
       "last_trg        0.120076\n",
       "last_fuml       0.120076\n",
       "last_ry         0.120076\n",
       "last_tdret      0.120076\n",
       "last_sra        0.120076\n",
       "last_ra         0.120076\n",
       "last_tdp        0.120076\n",
       "last_ints       0.120076\n",
       "last_py         0.120076\n",
       "last_pc         0.120076\n",
       "last_rety       0.120076\n",
       "humd            0.039388\n",
       "career_pa       0.033422\n",
       "career_trg      0.033422\n",
       "career_tdret    0.033422\n",
       "career_rety     0.033422\n",
       "career_ret      0.033422\n",
       "career_tdrec    0.033422\n",
       "career_recy     0.033422\n",
       "career_rec      0.033422\n",
       "career_fuml     0.033422\n",
       "career_tdr      0.033422\n",
       "career_ry       0.033422\n",
       "career_sra      0.033422\n",
       "career_ra       0.033422\n",
       "career_tdp      0.033422\n",
       "career_ints     0.033422\n",
       "career_py       0.033422\n",
       "career_pc       0.033422\n",
       "wdir            0.029693\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns with missing values but less than or equal to 25%\n",
    "impute_cols = missing_data_pct[(missing_data_pct <= 0.25) & (missing_data_pct > 0)].sort_values(ascending=False)\n",
    "impute_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take action on missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop columns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with missing data greater than 25%\n",
    "#store the column names\n",
    "missing_cols_del = missing_data_pct[missing_data_pct > 0.25].sort_values(ascending=False).index\n",
    "#drop the columns and store as new dataframe\n",
    "train_wr_miss = train_wr.drop(missing_cols_del, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21453, 171)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape\n",
    "train_wr_miss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute the rest of the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build simple imputers for both numeric and categorical features\n",
    "numeric_impute = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "cat_impute = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of all of the features to impute\n",
    "missing_values_df = train_wr_miss.drop(train_wr_miss.columns.difference(impute_cols.index), axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_pa', 'last_pc', 'last_py', 'last_ints', 'last_tdp', 'last_ra',\n",
       "       'last_sra', 'last_ry', 'last_tdr', 'last_fuml', 'last_trg', 'last_rec',\n",
       "       'last_recy', 'last_tdrec', 'last_ret', 'last_rety', 'last_tdret',\n",
       "       'career_pa', 'career_pc', 'career_py', 'career_ints', 'career_tdp',\n",
       "       'career_ra', 'career_sra', 'career_ry', 'career_tdr', 'career_fuml',\n",
       "       'career_trg', 'career_rec', 'career_recy', 'career_tdrec', 'career_ret',\n",
       "       'career_rety', 'career_tdret', 'temp', 'wdir', 'humd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the columns that need to use the numeric imputation and the categorical imputation\n",
    "impute_numeric_col = missing_values_df.select_dtypes(include=np.number).columns\n",
    "impute_cat_col = missing_values_df.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below attempts to handle infinity values; This is not an issue right now but something to be aware of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boolean if the column has 'inf' values or not\n",
    "#inf_cols = np.isinf(train_wr_miss.loc[:, impute_numeric_col]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns that have 'inf' values\n",
    "#inf_cols2 = list(train_wr_miss.loc[:, impute_numeric_col].columns.to_series()[inf_cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute numeric columns\n",
    "imputed_numeric_df = pd.DataFrame(numeric_impute.fit_transform(train_wr_miss.loc[:, impute_numeric_col]), columns=impute_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute categorical columns\n",
    "imputed_cat_df = pd.DataFrame(cat_impute.fit_transform(train_wr_miss.loc[:, impute_cat_col]), columns=impute_cat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some analysis on the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wr_miss[train_wr_miss['last_pa'].isna()].to_csv('C:/Users/Joe/Desktop/missing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
