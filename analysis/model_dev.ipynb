{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Model Development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://raw.githubusercontent.com/jchristo12/fantasy_football/master/data/full_data.csv\n",
    "df = pd.read_csv('https://github.com/jchristo12/fantasy_football/blob/master/data/full_data.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pk', 'gid', 'seas', 'wk', 'player', 'fname', 'lname', 'full_name',\n",
       "       'team', 'pos1',\n",
       "       ...\n",
       "       'humd', 'ou', 'sprv', 'ptsv', 'ptsh', 'udog', 'gen_cond', 'udog_binary',\n",
       "       'def_team', 'f_pts'],\n",
       "      dtype='object', length=161)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that have NaN for the shifted variables\n",
    "df_clean = df[~df.loc[:,'seas_pa':'seas_tdret'].isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are only focused on offensive players right now. Therefore, we will specifiy the positions we want to retain in the data and remove everyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#store positions we are concerned about; will use these to filter out \n",
    "pos_of_interest = ['QB', 'RB', 'WR', 'TE']\n",
    "#filter out positions we don't care about\n",
    "df_clean2 = df_clean[df_clean['pos1'].isin(pos_of_interest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert each column to the appropriate data type (i.e. make the categorical data categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the column types\n",
    "col_dtypes = {'category': ['seas', 'wk', 'pos1', 'team', 'udog', 'dv', 'v', 'h', 'day', 'cond', 'stad', 'wdir',\n",
    "                          'surf', 'gen_cond', 'def_team']}\n",
    "#flip the key and values around so they will work in the argument for 'astype()'\n",
    "col_dtypes_alt = {old: new for new, old_all in col_dtypes.items() for old in old_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df_clean2.astype(col_dtypes_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segment out the WR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wr = df_clean2.loc[df_clean2['pos1']=='WR', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only focus on week 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wr10 = df_wr.loc[df_wr['wk'] == 10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only focusing on the WR data right now. Will need to build this so that each action is extendable to the other positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the random seed for reproducability\n",
    "random.seed(837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break out the data between training and test\n",
    "train_wr, test_wr = train_test_split(df_wr10, train_size=0.75, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1625, 161) (542, 161)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data\n",
    "print(train_wr.shape, test_wr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a series of percent of missing data\n",
    "missing_data_pct = train_wr.isna().sum() / train_wr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roll_td_to_int           0.992000\n",
       "seas_td_to_int           0.990154\n",
       "roll_yds_per_comp        0.985846\n",
       "seas_yds_per_comp        0.980923\n",
       "roll_comp_pct            0.972923\n",
       "seas_comp_pct            0.960000\n",
       "career_td_to_int         0.857846\n",
       "career_yds_per_comp      0.846769\n",
       "career_comp_pct          0.798769\n",
       "roll_carry_to_td         0.737231\n",
       "roll_ryds_per_carry      0.736615\n",
       "roll_avg_ret             0.685538\n",
       "roll_ret_to_td           0.685538\n",
       "roll_carry_to_fuml       0.662769\n",
       "seas_ret_to_td           0.653538\n",
       "seas_avg_ret             0.653538\n",
       "seas_carry_to_td         0.633231\n",
       "seas_ryds_per_carry      0.632615\n",
       "career_avg_ret           0.600000\n",
       "career_ret_to_td         0.600000\n",
       "seas_carry_to_fuml       0.533538\n",
       "career_ryds_per_carry    0.328615\n",
       "career_carry_to_td       0.327385\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all columns with missing data that is greater than 25%\n",
    "missing_data_pct[missing_data_pct > 0.25].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_carry_to_fuml    0.246154\n",
       "humd                    0.230154\n",
       "wdir                    0.217846\n",
       "temp                    0.140923\n",
       "career_rec_to_td        0.136615\n",
       "career_yds_per_rec      0.132923\n",
       "last_tdr                0.131692\n",
       "last_rety               0.131692\n",
       "last_ret                0.131692\n",
       "last_tdrec              0.131692\n",
       "last_recy               0.131692\n",
       "last_rec                0.131692\n",
       "last_trg                0.131692\n",
       "last_fuml               0.131692\n",
       "last_tdret              0.131692\n",
       "last_ry                 0.131692\n",
       "last_sra                0.131692\n",
       "last_ra                 0.131692\n",
       "last_tdp                0.131692\n",
       "last_ints               0.131692\n",
       "last_py                 0.131692\n",
       "last_pc                 0.131692\n",
       "last_pa                 0.131692\n",
       "career_catch_pct        0.125538\n",
       "dv                      0.074462\n",
       "roll_rec_to_td          0.072000\n",
       "roll_yds_per_rec        0.072000\n",
       "seas_rec_to_td          0.062154\n",
       "seas_yds_per_rec        0.062154\n",
       "roll_catch_pct          0.048000\n",
       "seas_catch_pct          0.041846\n",
       "career_ra               0.038769\n",
       "career_tdp              0.038769\n",
       "career_tdret            0.038769\n",
       "career_rety             0.038769\n",
       "career_ret              0.038769\n",
       "career_tdrec            0.038769\n",
       "career_recy             0.038769\n",
       "career_rec              0.038769\n",
       "career_trg              0.038769\n",
       "career_fuml             0.038769\n",
       "career_tdr              0.038769\n",
       "career_ry               0.038769\n",
       "career_pa               0.038769\n",
       "career_pc               0.038769\n",
       "career_py               0.038769\n",
       "career_ints             0.038769\n",
       "career_sra              0.038769\n",
       "cond                    0.026462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns with missing values but less than or equal to 25%\n",
    "missing_data_pct[(missing_data_pct <= 0.25) & (missing_data_pct > 0)].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take action on missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop columns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with missing data greater than 25%\n",
    "#store the column names\n",
    "missing_cols_del = missing_data_pct[missing_data_pct > 0.25].sort_values(ascending=False).index\n",
    "#drop the columns and store as new dataframe\n",
    "train_wr_miss = train_wr.drop(missing_cols_del, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape\n",
    "train_wr_miss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute the rest of the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_impute(df, cols):\n",
    "    #initialize a list to store imputed features\n",
    "    imputed_features = []\n",
    "    \n",
    "    #loop thru all features that have missing values\n",
    "    for c in cols:\n",
    "        #store the column datatype\n",
    "        data_type = df[c].dtype\n",
    "        #store the target variable separate\n",
    "        target = df[c].values\n",
    "        #store the features separate\n",
    "        features = df.drop(c, axis=1).values\n",
    "        \n",
    "        #perform the imputation\n",
    "        if (data_type == 'category') | (data_type == 'bool'):\n",
    "            #Decision tree for categorical variable\n",
    "            Ctree = DecisionTreeClassifier(criterion='gini', random_state=100, min_samples_leaf=3)\n",
    "            Ctree.fit(features, target)\n",
    "            output = Ctree.predict(target)\n",
    "        else:\n",
    "            try:\n",
    "                #Decision tree for regression variables\n",
    "                Rtree = DecisionTreeRegressor(criterion='mse', random_state=100, min_samples_leaf=3)\n",
    "                Rtree.fit(features, target)\n",
    "                output = Rtree.predict(target)\n",
    "            except:\n",
    "                #use the average value to impute missing values\n",
    "                print('Decision tree could not be used for imputation')\n",
    "                print('Average value used')\n",
    "                mean_impute = SimpleImputer(strategy='mean')\n",
    "                output = mean_impute.fit_transform(target)\n",
    "        \n",
    "        #store the missing values\n",
    "        result = pd.Series(output).rename('imp_' + c)\n",
    "        imputed_features.append(result)\n",
    "    \n",
    "    #concat all series into a dataframe\n",
    "    final_df = pd.concat(imputed_features, axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the columns with missing data\n",
    "low_missing_cols = missing_data_pct[(missing_data_pct <= 0.25) & (missing_data_pct > 0)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the argments for testing\n",
    "c = low_missing_cols[0]\n",
    "df = train_wr_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the column type\n",
    "col_data_type = df[c].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the target\n",
    "target = df[c].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the features\n",
    "features = df.drop(c, axis=1).loc[:, 'team':].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree classifier\n",
    "tree = DecisionTreeClassifier(criterion='gini', random_state=212, min_samples_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-59712ba9b24c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fit the tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NE'"
     ]
    }
   ],
   "source": [
    "#fit the tree\n",
    "fit = tree.fit(features, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
